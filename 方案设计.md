# DbRheo 技术设计报告

## 项目概述

本报告详细说明 DbRheo 项目中两种数据查询方案的技术设计：
- **方案A：Baseline Agent**（基于 CSV 文件的 LLM 查询方案）
- **方案B：DbRheo NL2SQL Agent**（基于数据库的自然语言查询方案）

---

## 一、问题集与数据集构建

### 1.1 数据集构建

#### 1.1.1 原始数据来源

**数据文件**：`baseline/课题数据(1).csv`

**数据规模**：
- 总行数：约 16,000 行
- 时间跨度：2005-01 至 2030-12
- 数据类型：销量数据、市场份额数据、预计算指标（同比/环比）

**数据字段**：
```csv
indicator_id, display_name, unit, value, date
```

**示例数据**：
```csv
IND001, "乘用车销量：比亚迪_秦PLUS：月", "辆", 15000, 2023-06-01
IND002, "乘用车销量：一汽大众_揽境：月", "辆", 4045, 2023-06-01
IND003, "乘用车市场份额：比亚迪_秦PLUS：月", "%", 2.5, 2023-06-01
```

#### 1.1.2 数据拆分策略

使用 `baseline/data_scripts/split_csv.py` 进行数据拆分：

**拆分逻辑**：
```python
# 测试集：包含预计算指标（同比/环比）
test_set = df[df['display_name'].str.contains('同比|环比')]

# 数据源：原始销量和市场份额数据
data_source = df[~df['display_name'].str.contains('同比|环比')]
```

**输出文件**：
1. **测试集**：`baseline/测试集_月同比.csv`
   - 用途：验证计算准确性
   - 内容：预计算的同比/环比指标
   - 不导入数据库

2. **数据源**：`baseline/数据源_销量.csv`
   - 用途：供两种方案查询使用
   - 内容：原始销量数据和市场份额数据
   - Baseline Agent 直接读取
   - DbRheo Agent 导入数据库后查询

#### 1.1.3 数据预处理对比

**方案A：Pandas 内存加载（baseline_agent_enhanced.py）**

启动时将整个 CSV 文件加载到内存：

```python
class EnhancedBaselineAgent:
    def __init__(self, csv_path: str):
        """
        初始化时加载整个CSV到内存
        """
        self.csv_path = csv_path
        self.df = pd.read_csv(csv_path)  # 一次性加载全部数据
        
        # 获取数据样例（用于LLM理解数据结构）
        self.sample_data = self.df.head(5).to_string()
        self.columns = list(self.df.columns)
        
        print(f"✅ 加载CSV: {len(self.df)}行")
        print(f"✅ 列名: {self.columns}")
```

**数据过滤流程**：

```python
def _filter_data(self, conditions: dict) -> pd.DataFrame:
    """
    使用 Pandas 进行数据过滤
    """
    filtered = self.df.copy()
    
    # 1. 时间过滤
    time_start = conditions.get('time_start')
    time_end = conditions.get('time_end')
    if time_start or time_end:
        filtered['time_prefix'] = filtered['data_time'].str[:7]
        time_mask = (filtered['time_prefix'] >= time_start) & \
                    (filtered['time_prefix'] <= time_end)
        filtered = filtered[time_mask]
    
    # 2. 品牌/车型关键词过滤
    brand_keywords = conditions.get('brand_keywords', [])
    model_keywords = conditions.get('model_keywords', [])
    
    if brand_keywords:
        brand_mask = pd.Series([False] * len(filtered))
        for keyword in brand_keywords:
            brand_mask |= filtered['display_name'].str.contains(keyword)
        filtered = filtered[brand_mask]
    
    if model_keywords:
        model_mask = pd.Series([False] * len(filtered))
        for keyword in model_keywords:
            model_mask |= filtered['display_name'].str.contains(keyword)
        filtered = filtered[model_mask]
    
    return filtered
```

**方案A特点**：
- 数据加载：启动时一次性加载全部数据到内存
- 数据格式：保持原始 CSV 格式（display_name 未解析）
- 过滤方式：Pandas 字符串匹配（contains）
- 优点：简单直接，无需额外处理
- 缺点：内存占用高，字符串匹配不精确

**方案B：结构化数据库存储**

使用 `baseline/data_scripts/import_to_sqlite.py` 将 CSV 拆分为结构化表：

**数据预处理对比表**：

| 维度 | 方案A（Baseline） | 方案B（DbRheo） |
|------|------------------|----------------|
| **处理方式** | 直接加载 CSV | 结构化拆分 |
| **存储形式** | Pandas DataFrame（内存） | 数据库表（磁盘） |
| **数据组织** | 单表（原始格式） | 双表（销量表+份额表） |
| **字段解析** | 保持原始 display_name | 解析为 brand + model |
| **索引优化** | 无索引 | B-Tree 索引（brand, date） |
| **查询方式** | Pandas 字符串匹配 | SQL WHERE 精确匹配 |
| **数据完整性** | 100%（全部加载） | 100%（精确查询） |
| **启动时间** | 较长（加载全部数据） | 较短（直接连接） |
| **内存占用** | 高（16,000行全部加载） | 低（按需查询） |
| **查询精度** | 低（字符串模糊匹配） | 高（字段精确匹配） |

**数据库设计**：

```sql
-- 表1：车型销量表
CREATE TABLE vehicle_sales (
    indicator_id TEXT,
    brand TEXT,           -- 品牌（从 display_name 解析）
    model TEXT,           -- 车型（从 display_name 解析）
    sales_volume REAL,    -- 销量（单位：辆）
    date TEXT             -- 日期（格式：YYYY-MM-DD）
);

-- 索引优化
CREATE INDEX idx_sales_brand ON vehicle_sales(brand);
CREATE INDEX idx_sales_date ON vehicle_sales(date);
CREATE INDEX idx_sales_brand_date ON vehicle_sales(brand, date);

-- 表2：市场份额表
CREATE TABLE market_share (
    indicator_id TEXT,
    brand TEXT,
    model TEXT,
    market_share REAL,    -- 市场份额（单位：%）
    date TEXT
);

-- 索引优化
CREATE INDEX idx_share_brand ON market_share(brand);
CREATE INDEX idx_share_date ON market_share(date);
```

**品牌车型解析**：
```python
def parse_brand_model(display_name):
    """
    从 display_name 解析品牌和车型
    示例：'乘用车销量：比亚迪_秦PLUS：月' -> ('比亚迪', '秦PLUS')
    """
    match = re.search(r'：(.+?)_(.+?)：', display_name)
    if match:
        return match.group(1), match.group(2)
    return None, None
```

**数据导入流程**：
1. 读取 CSV 文件
2. 解析品牌和车型
3. 根据 unit 字段分类：
   - `unit="辆"` → vehicle_sales 表
   - `unit="%"` → market_share 表
4. 批量插入数据库
5. 创建索引优化查询

### 1.2 问题集构建

#### 1.2.1 问题集设计原则

**覆盖维度**：
1. **基础取数**：单月销量、单年销量
2. **时间区间**：季度、半年、全年
3. **计算指标**：同比、环比、增长率
4. **聚合查询**：求和、平均、最大最小
5. **排名查询**：TOP N、排序
6. **多维度**：品牌对比、车型对比
7. **边界测试**：空值、极值、特殊字符

#### 1.2.2 问题集文件

**文件位置**：`test/question/automotive_questions_list_100.csv`

**问题格式**：
```csv
问题ID, 问题内容
Q1, 2023-06，一汽大众揽境的销量是多少？
Q2, 2023年比亚迪的总销量是多少？
Q3, 一汽大众在2023年6月的销量同比增长是多少？
Q4, 2023-12，销量最高的具体车型是哪款？
...
```

**问题类型分布**（100题）：
- 基础取数：30题（30%）
- 聚合查询：25题（25%）
- 同比环比：20题（20%）
- 排名查询：15题（15%）
- 复杂查询：10题（10%）

#### 1.2.3 标准答案构建

**文件位置**：`test/answer/automotive_answers_100.csv`

**答案格式**：
```csv
问题ID, 标准答案
Q1, 4045
Q2, 150000
Q3, -11.56%
Q4, 比亚迪秦PLUS
...
```

**答案来源**：
1. **直接取数**：从数据源直接查询
2. **手工计算**：使用 Excel/Python 验证

**答案格式规范**：
- 数值：纯数字（如 `4045`）
- 百分比：带 % 符号，保留小数点后14位（如 `-11.56%`）
- 文本：品牌/车型名称（如 `比亚迪秦PLUS`）

---

## 二、大模型取数框架设计

### 2.1 方案A：Baseline Agent 框架

#### 2.1.1 整体架构

```
用户问题
    ↓
LLM 生成过滤条件
    ↓
Pandas 数据过滤
    ↓
LLM 分析结果
    ↓
返回答案
```

#### 2.1.2 核心实现（baseline_agent_enhanced.py）

**第一步：LLM 生成过滤条件**

```python
class EnhancedBaselineAgent:
    def generate_filter_conditions(self, question: str) -> dict:
        """
        让 LLM 生成结构化的过滤条件
        """
        prompt = f"""
        根据问题生成数据过滤条件（JSON格式）：
        
        问题：{question}
        
        返回格式：
        {{
            "brand": "品牌名称或null",
            "model": "车型名称或null",
            "date_start": "开始日期或null",
            "date_end": "结束日期或null",
            "metric": "销量或市场份额"
        }}
        """
        
        response = self.llm.generate(prompt)
        return json.loads(response)
```

**第二步：Pandas 数据过滤**

```python
def filter_data(self, df: pd.DataFrame, conditions: dict) -> pd.DataFrame:
    """
    根据条件过滤数据
    """
    filtered = df.copy()
    
    # 品牌过滤
    if conditions.get('brand'):
        filtered = filtered[
            filtered['display_name'].str.contains(conditions['brand'])
        ]
    
    # 车型过滤
    if conditions.get('model'):
        filtered = filtered[
            filtered['display_name'].str.contains(conditions['model'])
        ]
    
    # 日期范围过滤
    if conditions.get('date_start'):
        filtered = filtered[filtered['date'] >= conditions['date_start']]
    if conditions.get('date_end'):
        filtered = filtered[filtered['date'] <= conditions['date_end']]
    
    # 指标类型过滤
    if conditions.get('metric') == '销量':
        filtered = filtered[filtered['unit'] == '辆']
    elif conditions.get('metric') == '市场份额':
        filtered = filtered[filtered['unit'] == '%']
    
    return filtered
```

**第三步：LLM 分析结果**

```python
def analyze_results(self, question: str, filtered_data: pd.DataFrame) -> str:
    """
    让 LLM 分析过滤后的数据并回答问题
    """
    # 将数据转换为文本
    data_text = filtered_data.to_string(index=False, max_rows=100)
    
    prompt = f"""
    根据以下数据回答问题：
    
    问题：{question}
    
    数据：
    {data_text}
    
    请进行必要的计算（求和、平均、同比等），并以【答案：XXX】格式返回。
    """
    
    response = self.llm.generate(prompt)
    return response
```

#### 2.1.3 优缺点分析

**优点**：
- ✅ 无需数据库，部署简单
- ✅ 适合小规模数据（< 100MB）
- ✅ 灵活性高，易于调试

**缺点**：
- ❌ LLM 计算大数字容易出错（±5% 误差）
- ❌ 数据量大时性能下降
- ❌ 无法利用数据库索引优化
- ❌ 准确率：70-85%

### 2.2 方案B：NL2SQL Agent 框架

#### 2.2.1 整体架构

```
用户问题
    ↓
Schema 探索（自动获取表结构）
    ↓
LLM 生成 SQL
    ↓
SQL 风险评估
    ↓
执行 SQL 查询
    ↓
结果后处理（可选：Python 计算）
    ↓
返回答案
```

#### 2.2.2 核心组件设计

**组件1：Schema 探索（schema_discovery.py）**

```python
class SchemaDiscovery:
    """
    自动探索数据库结构
    """
    async def discover_schema(self, db_adapter) -> dict:
        """
        获取数据库完整结构
        """
        schema = {
            "tables": [],
            "relationships": []
        }
        
        # 获取所有表
        tables = await db_adapter.get_tables()
        
        for table in tables:
            # 获取表结构
            columns = await db_adapter.get_columns(table)
            indexes = await db_adapter.get_indexes(table)
            sample_data = await db_adapter.get_sample_data(table, limit=3)
            
            schema["tables"].append({
                "name": table,
                "columns": columns,
                "indexes": indexes,
                "sample_data": sample_data
            })
        
        return schema
```

**组件2：SQL 生成（sql_tool.py）**

```python
class SQLTool:
    """
    SQL 查询工具
    """
    async def generate_sql(self, question: str, schema: dict) -> str:
        """
        根据问题和 Schema 生成 SQL
        """
        prompt = f"""
        你是一个 SQL 专家。根据问题和数据库结构生成 SQL 查询。
        
        数据库结构：
        {json.dumps(schema, indent=2, ensure_ascii=False)}
        
        问题：{question}
        
        要求：
        1. 只返回 SQL 语句，不要解释
        2. 使用标准 SQL 语法
        3. 考虑性能优化（使用索引）
        4. 处理可能的 NULL 值
        
        SQL：
        """
        
        sql = await self.llm.generate(prompt)
        return self.clean_sql(sql)
```

**组件3：SQL 风险评估（risk_evaluator.py）**

```python
class RiskEvaluator:
    """
    SQL 风险评估
    """
    DANGEROUS_KEYWORDS = [
        'DROP', 'DELETE', 'TRUNCATE', 'ALTER', 
        'CREATE', 'INSERT', 'UPDATE', 'GRANT', 'REVOKE'
    ]
    
    def evaluate_risk(self, sql: str) -> dict:
        """
        评估 SQL 风险等级
        """
        sql_upper = sql.upper()
        
        # 检查危险关键词
        dangerous_found = []
        for keyword in self.DANGEROUS_KEYWORDS:
            if keyword in sql_upper:
                dangerous_found.append(keyword)
        
        if dangerous_found:
            return {
                "risk_level": "HIGH",
                "reason": f"包含危险操作：{', '.join(dangerous_found)}",
                "allow_execution": False
            }
        
        # 检查是否只读
        if sql_upper.strip().startswith('SELECT'):
            return {
                "risk_level": "LOW",
                "reason": "只读查询",
                "allow_execution": True
            }
        
        return {
            "risk_level": "MEDIUM",
            "reason": "未知操作类型",
            "allow_execution": False
        }
```

**组件4：数据库适配器（adapters/）**

```python
class SQLiteAdapter(BaseAdapter):
    """
    SQLite 数据库适配器
    """
    async def execute_query(self, sql: str) -> list:
        """
        执行 SQL 查询
        """
        async with aiosqlite.connect(self.db_path) as db:
            async with db.execute(sql) as cursor:
                columns = [desc[0] for desc in cursor.description]
                rows = await cursor.fetchall()
                
                # 转换为字典列表
                results = []
                for row in rows:
                    results.append(dict(zip(columns, row)))
                
                return results
    
    async def get_tables(self) -> list:
        """
        获取所有表名
        """
        sql = """
        SELECT name FROM sqlite_master 
        WHERE type='table' AND name NOT LIKE 'sqlite_%'
        """
        results = await self.execute_query(sql)
        return [r['name'] for r in results]
    
    async def get_columns(self, table: str) -> list:
        """
        获取表的列信息
        """
        sql = f"PRAGMA table_info({table})"
        results = await self.execute_query(sql)
        
        columns = []
        for r in results:
            columns.append({
                "name": r['name'],
                "type": r['type'],
                "nullable": not r['notnull'],
                "primary_key": bool(r['pk'])
            })
        
        return columns
```

**组件5：对话管理（core/chat.py）**

```python
class Chat:
    """
    对话管理器
    """
    def __init__(self, llm_service, db_adapter):
        self.llm = llm_service
        self.db = db_adapter
        self.memory = ConversationMemory()
        self.tools = self._init_tools()
    
    def _init_tools(self):
        """
        初始化工具集
        """
        return {
            "sql_query": SQLTool(self.llm, self.db),
            "schema_discovery": SchemaDiscovery(self.db),
            "python_execute": PythonExecuteTool(),
            "file_read": FileReadTool(),
            "file_write": FileWriteTool()
        }
    
    async def process_message(self, user_message: str) -> str:
        """
        处理用户消息
        """
        # 1. 添加到对话历史
        self.memory.add_message("user", user_message)
        
        # 2. 获取 Schema（首次或需要时）
        if not self.memory.has_schema():
            schema = await self.tools["schema_discovery"].discover_schema()
            self.memory.set_schema(schema)
        
        # 3. 让 LLM 决定使用哪个工具
        tool_decision = await self.llm.decide_tool(
            user_message, 
            self.memory.get_context(),
            list(self.tools.keys())
        )
        
        # 4. 执行工具
        if tool_decision["tool"] == "sql_query":
            result = await self.tools["sql_query"].execute(
                user_message,
                self.memory.get_schema()
            )
        elif tool_decision["tool"] == "python_execute":
            result = await self.tools["python_execute"].execute(
                tool_decision["code"]
            )
        
        # 5. 生成最终回复
        response = await self.llm.generate_response(
            user_message,
            result,
            self.memory.get_context()
        )
        
        # 6. 添加到对话历史
        self.memory.add_message("assistant", response)
        
        return response
```

#### 2.2.3 Prompt 工程

**System Prompt（core/prompts.py）**：

```python
DATABASE_AGENT_SYSTEM_PROMPT = """
你是一个专业的数据库查询助手，擅长将自然语言转换为 SQL 查询。

你的能力：
1. 理解用户的自然语言问题
2. 分析数据库结构（表、列、索引）
3. 生成高效的 SQL 查询
4. 执行 SQL 并解释结果
5. 必要时使用 Python 进行复杂计算

工作流程：
1. 分析问题，确定需要查询的表和字段
2. 生成 SQL 查询（优先使用索引）
3. 执行查询获取数据
4. 如需复杂计算（同比、环比），使用 Python
5. 以【答案：XXX】格式返回结果

注意事项：
- 只生成 SELECT 查询，不要修改数据
- 处理可能的 NULL 值
- 日期格式统一为 YYYY-MM-DD
- 数值计算保留2位小数
"""
```

**SQL 生成 Prompt**：

```python
SQL_GENERATION_PROMPT = """
根据问题和数据库结构生成 SQL 查询。

数据库结构：
{schema}

问题：{question}

示例：
问题：2023-06，一汽大众揽境的销量是多少？
SQL：
SELECT sales_volume 
FROM vehicle_sales 
WHERE brand = '一汽大众' 
  AND model = '揽境' 
  AND date = '2023-06-01';

现在生成 SQL：
"""
```

#### 2.2.4 优缺点分析

**优点**：
- ✅ 准确率高：95-100%
- ✅ SQL 聚合计算准确
- ✅ 支持大规模数据
- ✅ 利用数据库索引优化
- ✅ 可扩展性强

**缺点**：
- ❌ 需要对数据进行结构化处理
- ❌ 需要数据库环境
- ❌ 需要维护数据库连接

---

## 三、性能对比

### 3.1 准确率对比

| 指标 | Baseline Agent | DbRheo Agent |
|------|---------------|--------------|
| 基础取数 | 85% | 100% |
| 聚合查询 | 75% | 100% |
| 同比环比 | 65% | 95% |
| 排名查询 | 70% | 100% |
| **总体准确率** | **70-85%** | **95-100%** |

### 3.2 性能对比

| 指标 | Baseline Agent | DbRheo Agent |
|------|---------------|--------------|
| 平均响应时间 | 2-3秒 | 1-2秒 |
| 数据量支持 | < 100MB | 无限制 |
| 并发支持 | 低 | 高 |
| 内存占用 | 高（加载全部数据） | 低（按需查询） |

### 3.3 成本对比

| 指标 | Baseline Agent | DbRheo Agent |
|------|---------------|--------------|
| Token 消耗 | 高（需要传输数据） | 低（只传输 Schema） |
| API 调用次数 | 2-3次/问题 | 1-2次/问题 |
| 基础设施 | 无需数据库 | 需要数据库 |

---

## 四、测试与评估框架

### 4.1 自动化测试流程

```python
# test/run_benchmark.py
class BenchmarkRunner:
    """
    Benchmark 测试运行器
    """
    def run_test(self, questions: list, answers: list):
        """
        运行测试
        """
        results = []
        
        for i, (question, std_answer) in enumerate(zip(questions, answers)):
            # 测试 DbRheo Agent
            dbrheo_result = self.test_dbrheo_agent(question)
            
            # 测试 Baseline Agent
            baseline_result = self.test_baseline_agent(question)
            
            # 评估结果
            dbrheo_correct = self.evaluate(dbrheo_result, std_answer)
            baseline_correct = self.evaluate(baseline_result, std_answer)
            
            results.append({
                "question": question,
                "standard_answer": std_answer,
                "dbrheo_answer": dbrheo_result,
                "dbrheo_correct": dbrheo_correct,
                "baseline_answer": baseline_result,
                "baseline_correct": baseline_correct
            })
        
        return self.generate_report(results)
```

### 4.2 评估指标

```python
class EvaluationManager:
    """
    评估管理器
    """
    def compare_answers(self, standard: str, actual: str) -> tuple:
        """
        比较答案
        """
        # 提取数值
        std_num = self.extract_number(standard)
        act_num = self.extract_number(actual)
        
        if std_num is not None and act_num is not None:
            # 数值比较（±5% 容差）
            diff_percent = abs(std_num - act_num) / std_num * 100
            if diff_percent <= 5:
                return True, f"数值匹配（误差{diff_percent:.2f}%）"
            else:
                return False, f"数值不匹配（误差{diff_percent:.2f}%）"
        
        # 文本比较
        if standard.strip() == actual.strip():
            return True, "文本完全匹配"
        elif standard in actual or actual in standard:
            return True, "文本部分匹配"
        else:
            return False, "文本不匹配"
```

---

## 五、总结与建议

### 5.1 方案选择建议

**选择 Baseline Agent 的场景**：
- 数据量小（< 10MB）
- 快速原型验证
- 无数据库环境
- 对准确率要求不高（70-85% 可接受）

**选择 DbRheo Agent 的场景**：
- 生产环境
- 数据量大（> 100MB）
- 对准确率要求高（> 95%）
- 需要复杂查询和聚合
- 需要高并发支持

### 5.2 未来优化方向

**Baseline Agent 优化**：
1. 引入向量检索（RAG）提高数据定位准确性
2. 使用更强大的 LLM（GPT-4）提高计算准确性
3. 增加结果验证机制

**DbRheo Agent 优化**：
1. 支持更多数据库类型（MongoDB、ClickHouse）
2. 增加查询缓存机制
3. 支持自然语言生成图表
4. 增加 SQL 优化建议

### 5.3 关键技术要点

1. **Schema 探索是关键**：准确的表结构信息是生成正确 SQL 的基础
2. **Prompt 工程很重要**：清晰的 Prompt 能显著提高 SQL 生成质量
3. **风险评估必不可少**：防止危险 SQL 操作
4. **测试集要全面**：覆盖各种查询场景
5. **评估要客观**：使用标准答案和自动化评估

---

## 附录

### A. 项目文件结构

```
DbRheo-CLI/
├── baseline/                    # Baseline Agent
│   ├── baseline_agent_enhanced.py
│   ├── 数据源_销量.csv
│   └── data_scripts/
├── packages/core/src/dbrheo/    # DbRheo Agent
│   ├── core/chat.py
│   ├── tools/sql_tool.py
│   ├── adapters/
│   └── services/
├── test/                        # 测试框架
│   ├── question/
│   ├── answer/
│   └── result/
└── gradio_app.py                # Web 界面
```

### B. 关键配置

```bash
# .env 配置
OPENAI_API_KEY=your_key
DATABASE_URL=sqlite:///db/vehicle_sales.db
BASELINE_CSV_PATH=baseline/数据源_销量.csv
```

### C. 运行命令

```bash
# 启动 Gradio 界面
python gradio_app.py

# 运行测试
cd test
python run_benchmark.py

# 运行单元测试
python test_evaluation.py
```

---

**报告日期**：2026-01-14  
**版本**：v1.0
